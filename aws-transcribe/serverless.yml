service: aws-transcribe-api

frameworkVersion: '4'

provider:
  name: aws
  runtime: python3.10
  region: us-east-1
  stage: ${opt:stage, 'dev'}
  timeout: 29  # Match API Gateway timeout limit
  memorySize: 1024
  
  environment:
    LAMBDA_RUNTIME: true
    PYTHONPATH: /var/task
    AWS_REGION1: ${self:provider.region}
    OUTPUT_S3_BUCKET_NAME: ${env:OUTPUT_S3_BUCKET_NAME, 'great-ai-hackathon-transcribe-output-${self:provider.stage}'}
  
  # Use existing IAM role (IAM roles are global)
  iam:
    role: arn:aws:iam::555086046901:role/s3-upload-api-dev-us-east-1-lambdaRole

functions:
  transcribe:
    handler: lambda_handler.transcribe_handler
    events:
      - http:
          path: transcribe
          method: post
          cors:
            origin: '*'
            headers:
              - Content-Type
              - X-Amz-Date
              - Authorization
              - X-Api-Key
              - X-Amz-Security-Token
              - X-Amz-User-Agent
            allowCredentials: false
  
  status:
    handler: lambda_handler.status_handler
    events:
      - http:
          path: status
          method: get
          cors:
            origin: '*'
            headers:
              - Content-Type
            allowCredentials: false
  
  health:
    handler: lambda_handler.health_handler
    events:
      - http:
          path: health
          method: get
          cors:
            origin: '*'
            headers:
              - Content-Type
            allowCredentials: false

  processUrl:
    handler: lambda_handler.process_url_handler
    events:
      - http:
          path: process-url
          method: post
          cors:
            origin: '*'
            headers:
              - Content-Type
              - X-Amz-Date
              - Authorization
              - X-Api-Key
              - X-Amz-Security-Token
              - X-Amz-User-Agent
            allowCredentials: false

# Remove resources section since we're using existing bucket
# resources:
#   Resources:
#     # S3 bucket creation removed - using existing bucket

package:
  patterns:
    - '!.git/**'
    - '!.venv/**'
    - '!__pycache__/**'
    - '!*.pyc'
    - '!.pytest_cache/**'
    - '!tests/**'
    - '!media/**'
    - '!log/**'
    - '!output/**'
    - '!test_*.py'
    - '!local_test.py'
    - '!deploy_lambda.py'
    - '!README*.md'
    - '!uv.lock'
    - 'lambda_handler.py'
    - 'requirements.txt'

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: false
    zip: false
    slim: false
    strip: false
    noDeps: false
    usePoetry: false
    useStaticCache: false
    invalidateCaches: true
    usePipenv: false
    pythonBin: python
    pipCmdExtraArgs:
      - --no-cache-dir
      - --upgrade
      - --force-reinstall